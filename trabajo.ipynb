{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import copy\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "import collections\n",
    "from typing import Counter\n",
    "import numpy as np\n",
    "\n",
    "#Accuracy\n",
    "def accuracy(M):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(len(M)):\n",
    "        for j in range(len(M)):\n",
    "            total += M[i][j]\n",
    "            if i == j:\n",
    "                correct+=M[i][j]\n",
    "    return correct/total\n",
    "\n",
    "# Precision\n",
    "def precision(M, index): #index es la posicion de la variable de interes\n",
    "    correct = M[index][index]\n",
    "    total = 0\n",
    "    for i in range(len(M)):\n",
    "        for j in range(len(M)):\n",
    "            if i == index:\n",
    "                total+= M[i][j]\n",
    "    if total == 0:\n",
    "        return 0\n",
    "\n",
    "    return correct/total\n",
    "\n",
    "# Recall\n",
    "def recall(M, index): #index es la posicion de la variable de interes\n",
    "    correct = M[index][index]\n",
    "    total = 0\n",
    "    for i in range(len(M)):\n",
    "        for j in range(len(M)):\n",
    "            if j == index:\n",
    "                total+= M[i][j]\n",
    "    if total == 0:\n",
    "        return 0\n",
    "\n",
    "    return correct/total\n",
    "\n",
    "# F1\n",
    "def F1_score(M,index):\n",
    "    P = precision(M,index)\n",
    "    R = recall(M,index)\n",
    "    if P+R == 0:\n",
    "        return 0\n",
    "    return (2*P*R)/(P+R)\n",
    "\n",
    "def macro_avg(func, M): #func es la metrica que queremos usar\n",
    "    accum = 0\n",
    "    for i in range(len(M)):\n",
    "        accum+=func(M,i)\n",
    "    return accum/len(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"dataset.txt\", \"r\")\n",
    "o = open(\"processed.txt\", \"w\")\n",
    "printable = set(string.printable)\n",
    "to_delete = ['<', '/', '|', '(', '+', '%', ':', '{', '}', '.', ',']\n",
    "\n",
    "bracketsOpen = False\n",
    "for line in f:\n",
    "    line = line.replace(\" - \", \"-\")\n",
    "    for word in line.split():\n",
    "        word = ''.join(filter(lambda x: x in printable, word))\n",
    "        word = word.replace('=', ' ')\n",
    "        word = word.replace('>', ' ')\n",
    "        word = word.replace(')', ' ')\n",
    "\n",
    "        for letter in to_delete:\n",
    "            word = word.replace(letter, '')\n",
    "        o.write(word + \" \")\n",
    "f.close()\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "bag = collections.defaultdict(int)\n",
    "f = open(\"processed.txt\", \"r\")\n",
    "for line in f:\n",
    "    for word in line.split():\n",
    "        if word in stop:\n",
    "            continue\n",
    "        bag[word] += 1\n",
    "bag = dict(sorted(bag.items(), key=lambda item: item[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"modestly\"\n",
    "pageSize = 500\n",
    "\n",
    "frequent_words = list(bag.keys())\n",
    "feature_index = frequent_words.index(feature)\n",
    "incidence_vector = [0] * len(frequent_words)\n",
    "pages = []\n",
    "pages.append('')\n",
    "f = open(\"processed.txt\", \"r\")\n",
    "for line in f:\n",
    "    for word in line.split():\n",
    "        pages[-1] += \" \" + word\n",
    "        if len(pages[-1].split()) >= pageSize:\n",
    "            pages.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageVectors = []\n",
    "\n",
    "for page in pages:\n",
    "    vector = copy.deepcopy(incidence_vector)\n",
    "    for word in page.split():\n",
    "        for i in range(len(frequent_words)):\n",
    "            if word == frequent_words[i]:\n",
    "                vector[i] += 1\n",
    "    pageVectors.append(vector)\n",
    "print(len(pageVectors))\n",
    "# vamos a separar la variable clase\n",
    "clases = []\n",
    "for page in pageVectors:\n",
    "    clase = page[feature_index]\n",
    "    clases.append(clase)\n",
    "    page.pop(feature_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 80\n",
    "\n",
    "# Casteamos las variables a arreglos de numpy:\n",
    "index_percent = int(len(pageVectors)*split/100)\n",
    "X = np.array(pageVectors[:index_percent])\n",
    "Y = np.array(clases[:index_percent])\n",
    "X_test = np.array(pageVectors[index_percent:])\n",
    "Y_test = np.array(clases[index_percent:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "confusion = confusion_matrix(Y_test,clf.predict(X_test))\n",
    "acc = round(accuracy(confusion)*100)\n",
    "prec = round(macro_avg(precision,confusion)*100)\n",
    "rec = macro_avg(recall,confusion)*100\n",
    "F1 = macro_avg(F1_score,confusion)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, Y)\n",
    "confusion = confusion_matrix(Y_test,clf.predict(X_test))\n",
    "acc = round(accuracy(confusion)*100)\n",
    "prec = round(macro_avg(precision,confusion)*100)\n",
    "rec = macro_avg(recall,confusion)*100\n",
    "F1 = macro_avg(F1_score,confusion)*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify=Y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
    "clf.predict_proba(X_test)\n",
    "confusion = confusion_matrix(Y_test,clf.predict(X_test))\n",
    "acc = round(accuracy(confusion)*100)\n",
    "prec = round(macro_avg(precision,confusion)*100)\n",
    "rec = macro_avg(recall,confusion)*100\n",
    "F1 = macro_avg(F1_score,confusion)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "reg = LinearRegression().fit(X, Y)\n",
    "reg.score(X, Y)\n",
    "confusion = confusion_matrix(Y_test,clf.predict(X_test))\n",
    "acc = round(accuracy(confusion)*100)\n",
    "prec = round(macro_avg(precision,confusion)*100)\n",
    "rec = macro_avg(recall,confusion)*100\n",
    "F1 = macro_avg(F1_score,confusion)*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = []\n",
    "tp.append(acc)\n",
    "tp.append(prec)\n",
    "tp.append(rec)\n",
    "tp.append(F1)"
   ]
  }
 ]
}